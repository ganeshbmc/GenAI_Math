{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"9ae31250","cell_type":"markdown","source":"# Beta VAE  ","metadata":{}},{"id":"0b74e4bb-5881-4ed9-9b7f-aab0629bd315","cell_type":"markdown","source":"## Steps  \n1. Import libraries  \n2. Prepare data  \n   ```Download  |  Transform  |  Dataloader```  \n3. Define parameters  \n   ```Model  |  Optimizer  |  Loss  |  Training  ```\n4. Build Model  \n   ```Components  ```\n5. Training loop  \n6. Visualize results  ","metadata":{}},{"id":"a4e0d705-b86a-4341-8e15-74d232231452","cell_type":"markdown","source":"## Import libraries  ","metadata":{}},{"id":"8085a938-b8cc-4733-a684-01813c3e0858","cell_type":"code","source":"# Import libraries\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F    # New import\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import save_image\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nimport time\nimport datetime\n\nprint(f\"Imports completed at {datetime.datetime.now()}\")\n\n# Device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Versions\nprint(f\"Torch: {torch.__version__}, TorchVision: {torchvision.__version__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T17:57:10.827805Z","iopub.execute_input":"2025-08-22T17:57:10.828524Z","iopub.status.idle":"2025-08-22T17:57:10.834225Z","shell.execute_reply.started":"2025-08-22T17:57:10.828498Z","shell.execute_reply":"2025-08-22T17:57:10.833492Z"}},"outputs":[{"name":"stdout","text":"Imports completed at 2025-08-22 17:57:10.830933\nUsing device: cuda\nTorch: 2.6.0+cu124, TorchVision: 0.21.0+cu124\n","output_type":"stream"}],"execution_count":28},{"id":"b4fb1f6e-eedb-4a7e-b4f3-02ca806b721c","cell_type":"markdown","source":"## Define parameters  ","metadata":{}},{"id":"4eac0b38-2cd1-4c05-aeea-f7676e24d659","cell_type":"code","source":"# Set seed for PyTorch\nseed = 42\ntorch.manual_seed(seed)\n\n# Data prep params\nbatch_size = 128\n\n# Model params\nlatent_dim = 20\nbeta_vae = 4.0\n\n# Optimizer params\nlearning_rate = 0.0002\n# beta1 = 0.5  # Adam optimizer beta1\n\n# # Loss params\n# criterion = nn.BCELoss()\n\n# Training params\nnum_epochs = 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T17:57:10.861965Z","iopub.execute_input":"2025-08-22T17:57:10.862155Z","iopub.status.idle":"2025-08-22T17:57:10.867530Z","shell.execute_reply.started":"2025-08-22T17:57:10.862141Z","shell.execute_reply":"2025-08-22T17:57:10.866883Z"}},"outputs":[],"execution_count":29},{"id":"bb24207a-d509-4906-845e-6ba7386a979d","cell_type":"markdown","source":"## Prepare data  ","metadata":{}},{"id":"04e2c8d4-2e75-4220-bf0b-5d7eed3a4f3f","cell_type":"code","source":"# Transform\ntransform = transforms.ToTensor()\nprint(f\"Transform to be applied:\\n{transform}\\n\")\n\n# Load MNIST\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\nprint(f\"Train data:\\n{train_dataset}\\n\")\n\n# Dataloader\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True) # Last batch will be 96 (6000 % 128) instead of 128, so drop to avoid problem with batch norm\nprint(f\"Data loader:\\n{train_loader}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T17:57:10.868358Z","iopub.execute_input":"2025-08-22T17:57:10.868698Z","iopub.status.idle":"2025-08-22T17:57:10.979029Z","shell.execute_reply.started":"2025-08-22T17:57:10.868681Z","shell.execute_reply":"2025-08-22T17:57:10.978122Z"}},"outputs":[{"name":"stdout","text":"Transform to be applied:\nToTensor()\n\nTrain data:\nDataset MNIST\n    Number of datapoints: 60000\n    Root location: ./data\n    Split: Train\n    StandardTransform\nTransform: ToTensor()\n\nData loader:\n<torch.utils.data.dataloader.DataLoader object at 0x7d3106979350>\n","output_type":"stream"}],"execution_count":30},{"id":"e5e33335-93ff-4f27-b361-09c98c2c40b3","cell_type":"markdown","source":"## Build Model  \n```Beta VAE```  \n\n**Probabilistic Neural Networks**  \n\n- Encoder\n    - Takes image, outputs mean and log var of latent space dim  \n- Reparametrization (z-sampler)\n    - Takes the mean and log var output by the Encoder and creates new z using epsilon (latent dim) from std normal  \n- Decoder\n    - Takes the z and outputs mean of x_hat (note that the var of x_hat is 1)  ","metadata":{}},{"id":"095fa2db-ca3b-46fb-b1c0-bcf7a53824f3","cell_type":"code","source":"class BetaVAE(nn.Module):\n    def __init__(self, latent_dim=20):\n        super(BetaVAE, self).__init__()\n        self.latent_dim = latent_dim\n\n        #--------------Encoder--------------\n        self.encoder = nn.Sequential(\n            # Input: (B, 1, 28, 28)\n            nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1),    # [B, 32, 14, 14]\n            nn.ReLU(True),\n            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),    # [B, 64, 7, 7]\n            nn.ReLU(True),\n            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),    # [B, 128, 4, 4]\n            nn.ReLU(True),\n        )\n        self.flatten = nn.Flatten()\n        self.mu = nn.Linear(128 * 4 * 4, self.latent_dim)\n        self.logvar = nn.Linear(128 * 4 * 4, self.latent_dim)\n\n        #--------------Decoder--------------\n        self.fc_decode = nn.Linear(self.latent_dim, 128*4*4)\n        self.decoder = nn.Sequential(\n            # Input: z (B, latent_dim)\n            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),    # [B, 64, 8, 8]\n            nn.ReLU(True),\n            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),    # [B, 32, 16, 16]\n            nn.ReLU(True),\n            nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1),    # [B, 1, 32, 32]\n            nn.Sigmoid(),\n        )\n\n    def encode(self, x):\n        h = self.encoder(x)\n        h_flat = self.flatten(h)\n        mu = self.mu(h_flat)\n        logvar = self.logvar(h_flat)\n        return mu, logvar\n\n    def reparameterize(self, mu, logvar):\n        eps = torch.randn_like(mu)\n        std = torch.exp(0.5 * logvar)\n        z = mu + std * eps\n        return z\n\n    def decode(self, z):\n        h = self.fc_decode(z)\n        h = h.view(-1, 128, 4, 4)\n        x_hat = self.decoder(h)\n        return x_hat[:, :, 28, 28]    # Crop to MNIST size\n        \n    def forward(self, x):\n        mu, logvar = self.encode(x)\n        z = self.reparameterize(mu, logvar)\n        x_hat = self.decode(z)\n        return x_hat, mu, logvar","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T17:57:10.980177Z","iopub.execute_input":"2025-08-22T17:57:10.980492Z","iopub.status.idle":"2025-08-22T17:57:10.992284Z","shell.execute_reply.started":"2025-08-22T17:57:10.980465Z","shell.execute_reply":"2025-08-22T17:57:10.991534Z"}},"outputs":[],"execution_count":31},{"id":"ada15298-f3d4-46e9-b6b2-ec30229fe7d5","cell_type":"code","source":"model = BetaVAE(latent_dim)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T17:57:10.993104Z","iopub.execute_input":"2025-08-22T17:57:10.993341Z","iopub.status.idle":"2025-08-22T17:57:11.023904Z","shell.execute_reply.started":"2025-08-22T17:57:10.993318Z","shell.execute_reply":"2025-08-22T17:57:11.023312Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"BetaVAE(\n  (encoder): Sequential(\n    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (5): ReLU(inplace=True)\n  )\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (mu): Linear(in_features=2048, out_features=20, bias=True)\n  (logvar): Linear(in_features=2048, out_features=20, bias=True)\n  (fc_decode): Linear(in_features=20, out_features=2048, bias=True)\n  (decoder): Sequential(\n    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (5): Sigmoid()\n  )\n)"},"metadata":{}}],"execution_count":32},{"id":"6eea0e57-61cb-436a-94c0-1967eb67afd2","cell_type":"markdown","source":"## Set up Optimizers  ","metadata":{}},{"id":"d9c722e0-3fa5-45f7-8a22-b5afaeb99c9c","cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=learning_rate)\noptimizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T17:57:11.025564Z","iopub.execute_input":"2025-08-22T17:57:11.025801Z","iopub.status.idle":"2025-08-22T17:57:11.034739Z","shell.execute_reply.started":"2025-08-22T17:57:11.025777Z","shell.execute_reply":"2025-08-22T17:57:11.034010Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 0\n)"},"metadata":{}}],"execution_count":33},{"id":"bc17d46d-6619-4fbd-a456-625a7ac4294f","cell_type":"markdown","source":"## Set up Loss functions  ","metadata":{}},{"id":"270fe978-9776-4318-9260-1c07c731225d","cell_type":"code","source":"def beta_vae_loss(x, x_hat, mu, logvar, beta=4.0):\n    # Recon loss + beta * KL Div\n\n    # Reconstruction loss: binary cross entropy\n    recon_loss = F.binary_cross_entropy(x_hat, x, reduction='sum')\n\n    # KL Divergence loss: between q(z|x) and N(0,I)\n    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n\n    # Total loss\n    loss = recon_loss + beta * kl_div\n\n    return loss, recon_loss, kl_div","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T17:57:11.035410Z","iopub.execute_input":"2025-08-22T17:57:11.035650Z","iopub.status.idle":"2025-08-22T17:57:11.049325Z","shell.execute_reply.started":"2025-08-22T17:57:11.035635Z","shell.execute_reply":"2025-08-22T17:57:11.048672Z"}},"outputs":[],"execution_count":34},{"id":"8f4bf6d3-c00a-4b90-8a36-4e349da1b381","cell_type":"markdown","source":"## Training loop  ","metadata":{}},{"id":"1667ffeb-e52f-41dd-9fca-89370abfd600","cell_type":"code","source":"def vae_trainer(num_epochs, latent_dim, beta):\n    losses, recon_losses, kl_divs = [], [], []\n    for epoch in range(num_epochs):\n        model.train()\n        total_loss, total_recon, total_kl = 0, 0, 0\n\n        for batch in train_loader:\n            x, _ = batch\n            x = x.to(device)\n\n            x_hat, mu, logvar = model(x)\n            loss, recon, kl = beta_vae_loss(x, x_hat, mu, logvar, beta)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            total_recon += recon.item()\n            total_kl += kl.item()\n\n        losses.append(total_loss / len(train_loader.dataset))\n        recon_losses.append(total_recon / len(train_loader.dataset))\n        kl_divs.append(total_kl / len(train_loader.dataset))\n\n        print(f\"Epoch {epoch+1}, Loss: {losses[-1]:.2f}, Recon: {recon_losses[-1]:.2f}, KL: {kl_divs[-1]:.2f}\")\n\n    return losses, recon_losses, kl_divs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T17:57:11.050044Z","iopub.execute_input":"2025-08-22T17:57:11.050770Z","iopub.status.idle":"2025-08-22T17:57:11.065447Z","shell.execute_reply.started":"2025-08-22T17:57:11.050748Z","shell.execute_reply":"2025-08-22T17:57:11.064741Z"}},"outputs":[],"execution_count":35},{"id":"af7cfae9-a77e-4532-9358-3b4d219eb700","cell_type":"markdown","source":"## Training  ","metadata":{}},{"id":"61a64a07-388b-42c4-9fcf-7411b248c941","cell_type":"code","source":"start = time.perf_counter()\nprint(f\"Training started at {start}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T17:57:11.066026Z","iopub.execute_input":"2025-08-22T17:57:11.066176Z","iopub.status.idle":"2025-08-22T17:57:11.084881Z","shell.execute_reply.started":"2025-08-22T17:57:11.066164Z","shell.execute_reply":"2025-08-22T17:57:11.084369Z"}},"outputs":[{"name":"stdout","text":"Training started at 5939.28236697\n","output_type":"stream"}],"execution_count":36},{"id":"0aa67012-6a8d-43b3-8487-d89142ef8bc8","cell_type":"code","source":"losses, recon_losses, kl_divs = vae_trainer(num_epochs=num_epochs, \n                                            latent_dim=latent_dim, \n                                            beta=beta_vae\n                                           )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T17:57:11.085505Z","iopub.execute_input":"2025-08-22T17:57:11.085734Z","iopub.status.idle":"2025-08-22T17:57:11.140901Z","shell.execute_reply.started":"2025-08-22T17:57:11.085714Z","shell.execute_reply":"2025-08-22T17:57:11.140017Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3363750787.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m losses, recon_losses, kl_divs = vae_trainer(num_epochs=num_epochs, \n\u001b[0m\u001b[1;32m      2\u001b[0m                                             \u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                             \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta_vae\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                            )\n","\u001b[0;32m/tmp/ipykernel_36/3182915334.py\u001b[0m in \u001b[0;36mvae_trainer\u001b[0;34m(num_epochs, latent_dim, beta)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta_vae_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/1290962846.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mx_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/1290962846.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mh_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"],"ename":"RuntimeError","evalue":"Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same","output_type":"error"}],"execution_count":37},{"id":"f2416e28-5968-499a-8a95-42af87185309","cell_type":"markdown","source":"## Code for visualizations  ","metadata":{}},{"id":"d2746da2-aaaa-4f8f-bb51-16d68cca8f51","cell_type":"code","source":"# Check training time\nelapsed = time.perf_counter() - start\nprint(f\"Training time: {datetime.timedelta(seconds=int(elapsed))} ({elapsed:.2f} s)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T17:57:11.141275Z","iopub.status.idle":"2025-08-22T17:57:11.141514Z","shell.execute_reply.started":"2025-08-22T17:57:11.141377Z","shell.execute_reply":"2025-08-22T17:57:11.141386Z"}},"outputs":[],"execution_count":null}]}