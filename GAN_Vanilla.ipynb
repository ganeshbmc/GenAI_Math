{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMcoI87D3TxV4xRyz6dcfq0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ganeshbmc/GenAI_Math/blob/main/GAN_Vanilla.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps  \n",
        "1. Import libraries  \n",
        "2. Prepare data  \n",
        "   ```Download  |  Transform  |  Dataloader```  \n",
        "3. Define parameters  \n",
        "   ```Model  |  Optimizer  |  Loss  |  Training  ```\n",
        "4. Build Model  \n",
        "   ```Components  ```\n",
        "5. Training loop  \n",
        "6. Visualize results  "
      ],
      "metadata": {
        "id": "g7Fw9r_Q0FnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries  "
      ],
      "metadata": {
        "id": "n_9EKk6A3gUO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PKeOhWPDzyTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a293dff6-c624-49d5-a37b-e2ea7c84eb67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imports completed at 2025-08-20 06:34:46.455147\n",
            "Using device: cuda\n",
            "Torch: 2.8.0+cu126, TorchVision: 0.23.0+cu126\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "print(f\"Imports completed at {datetime.datetime.now()}\")\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Versions\n",
        "print(f\"Torch: {torch.__version__}, TorchVision: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define parameters  "
      ],
      "metadata": {
        "id": "uxCuW4RgM4Qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for PyTorch\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Data prep params\n",
        "batch_size = 128\n",
        "\n",
        "# Model params\n",
        "noise_dim = 100     # z_dim\n",
        "img_dim = 28 * 28 # MNIST size\n",
        "\n",
        "# Optimizer params\n",
        "learning_rate = 0.0002\n",
        "\n",
        "# # Loss params\n",
        "# criterion = nn.BCELoss()\n",
        "\n",
        "# Training params\n",
        "num_epochs = 2\n",
        "generator_rounds = 1\n",
        "discriminator_rounds = 1"
      ],
      "metadata": {
        "id": "jrAIgkbmM0Jb"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data  "
      ],
      "metadata": {
        "id": "Tf-hpM2r3lJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
        "])\n",
        "print(f\"Transform to be applied:\\n{transform}\\n\")\n",
        "\n",
        "# Load MNIST\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "print(f\"Train data:\\n{train_dataset}\\n\")\n",
        "\n",
        "# Dataloader\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "print(f\"Data loader:\\n{train_loader}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4rOxJbJ3XjQ",
        "outputId": "5c7d326b-4766-4ba1-96f0-dc70804540c2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transform to be applied:\n",
            "Compose(\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5,), std=(0.5,))\n",
            ")\n",
            "\n",
            "Train data:\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.5,), std=(0.5,))\n",
            "           )\n",
            "\n",
            "Data loader:\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7b1a7e5c8500>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model  \n",
        "```Vanilla GAN```  \n",
        "- MLP as neural network  \n",
        "\n",
        "Generator\n",
        "- noise_dim -> hidden layers -> img_dim with ReLU and Tanh  \n",
        "\n",
        "Discriminator\n",
        "- img_dim -> hidden layers -> 1 with Sigmoid activation  "
      ],
      "metadata": {
        "id": "2e-FX05bORCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, noise_dim, img_dim):\n",
        "    super(Generator, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        # MLP\n",
        "        nn.Linear(noise_dim, 256),\n",
        "        nn.ReLU(True),\n",
        "        nn.Linear(256, 512),\n",
        "        nn.ReLU(True),\n",
        "        nn.Linear(512, 1024),\n",
        "        nn.ReLU(True),\n",
        "        nn.Linear(1024, img_dim),\n",
        "        nn.Tanh()   # Because we normalized images to [-1, 1]\n",
        "    )\n",
        "\n",
        "  def forward(self, z):\n",
        "    return self.model(z)"
      ],
      "metadata": {
        "id": "aOoq4dMUOQFK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator(noise_dim=noise_dim, img_dim=img_dim)\n",
        "generator"
      ],
      "metadata": {
        "id": "C1LCMEsxRNut",
        "outputId": "6678f28c-5ea4-4049-c9f3-99fa8f6d8466",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (model): Sequential(\n",
              "    (0): Linear(in_features=100, out_features=256, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Linear(in_features=512, out_features=1024, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=1024, out_features=784, bias=True)\n",
              "    (7): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, img_dim):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(img_dim, 512),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Linear(256, 1),\n",
        "        nn.Sigmoid()    # Outputs probability between 0 and 1\n",
        "    )\n",
        "\n",
        "  def forward(self, img):\n",
        "    o = self.model(img)\n",
        "    return o"
      ],
      "metadata": {
        "id": "T2WF8rteTSIv"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = Discriminator(img_dim)\n",
        "discriminator"
      ],
      "metadata": {
        "id": "_14zmS9HUg9w",
        "outputId": "69db1547-0b01-4f53-9546-8c607d93de03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (model): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
              "    (5): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up Optimizers  "
      ],
      "metadata": {
        "id": "009Y2WceVaRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g_optim = optim.Adam(generator.parameters(), lr=learning_rate)\n",
        "g_optim"
      ],
      "metadata": {
        "id": "SO8cadsZVKaE",
        "outputId": "644778ef-e665-4a2e-f562-e40c2c53458e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    capturable: False\n",
              "    decoupled_weight_decay: False\n",
              "    differentiable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.0002\n",
              "    maximize: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_optim = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
        "d_optim"
      ],
      "metadata": {
        "id": "Hk0BdtVIVwC4",
        "outputId": "b2205bb4-5f46-4f59-cf22-445b2d930ed5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    capturable: False\n",
              "    decoupled_weight_decay: False\n",
              "    differentiable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.0002\n",
              "    maximize: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up Loss functions  "
      ],
      "metadata": {
        "id": "P87c8mF3V8Hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "criterion"
      ],
      "metadata": {
        "id": "n0EQvGQcV7z2",
        "outputId": "a8e0e1a3-9f1c-4634-c54a-89dbe2363fa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCELoss()"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code for visualizations  "
      ],
      "metadata": {
        "id": "ZA1kqjkPWfVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_generated_images(epoch, generator, fixed_noise):\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        fake_imgs = generator(fixed_noise).reshape(-1, 1, 28, 28)\n",
        "        fake_imgs = fake_imgs * 0.5 + 0.5  # De-normalize\n",
        "\n",
        "    grid = torchvision.utils.make_grid(fake_imgs, nrow=8)\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
        "    plt.title(f'Generated Images at Epoch {epoch}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    generator.train()"
      ],
      "metadata": {
        "id": "FK-hef4WWgEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop  \n",
        "- Visualize results every 10 epochs  "
      ],
      "metadata": {
        "id": "kRWGwu29WXRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gan_trainer(train_loader, ):\n",
        "  fixed_noise = torch.randn(64, noise_dim).to(device)  # For consistent visualization\n",
        "\n",
        "  # Training loop\n",
        "  for epoch in range(num_epochs):\n",
        "    pass\n",
        "\n",
        "  # Visualize\n",
        "    if (epoch+1) % 10 == 0:\n",
        "      print(f\"Epoch: [{epoch+1}/{num_epochs}]\")\n",
        "      print(f\"Discriminator loss = {d_loss.item():.4f}\")\n",
        "      print(f\"Generator loss = {g_loss.item():.4f}\")\n",
        "      show_generated_images(epoch=epoch+1, generator=generator, fixed_noise=fixed_noise)"
      ],
      "metadata": {
        "id": "AYs8k5_cWZtB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}