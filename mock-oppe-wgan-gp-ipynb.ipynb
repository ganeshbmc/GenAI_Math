{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-22T18:54:54.159299Z","iopub.execute_input":"2025-08-22T18:54:54.159469Z","iopub.status.idle":"2025-08-22T18:54:56.685635Z","shell.execute_reply.started":"2025-08-22T18:54:54.159452Z","shell.execute_reply":"2025-08-22T18:54:56.685085Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Steps  \n1. Import libraries  \n2. Prepare data  \n   ```Download  |  Transform  |  Dataloader```  \n3. Define parameters  \n   ```Model  |  Optimizer  |  Loss  |  Training  ```\n4. Build Model  \n   ```Components  ```\n5. Training loop  \n6. Visualize results  ","metadata":{}},{"cell_type":"code","source":"# Import libraries\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F    # New import\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import save_image\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nimport time\nimport datetime\n\nprint(f\"Imports completed at {datetime.datetime.now()}\")\n\n# Device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Versions\nprint(f\"Torch: {torch.__version__}, TorchVision: {torchvision.__version__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T18:56:21.431240Z","iopub.execute_input":"2025-08-22T18:56:21.431729Z","iopub.status.idle":"2025-08-22T18:56:32.080262Z","shell.execute_reply.started":"2025-08-22T18:56:21.431703Z","shell.execute_reply":"2025-08-22T18:56:32.079600Z"}},"outputs":[{"name":"stdout","text":"Imports completed at 2025-08-22 18:56:31.990100\nUsing device: cuda\nTorch: 2.6.0+cu124, TorchVision: 0.21.0+cu124\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Set seed for PyTorch\nseed = 42\ntorch.manual_seed(seed)\n\n# Data prep params\nbatch_size = 128\n\n# Model params\nz_dim = 100     # Size of noise vector\nimg_dim = 28       # MNIST size\nchannels = 1        # Gray scale\nimg_shape = (channels, img_dim, img_dim) # MNIST shape\n\n# Optimizer params\nlearning_rate = 0.0002\n# beta1 = 0.5  # Adam optimizer beta1\n\n# # Loss params\n# criterion = nn.BCELoss()\n\n# Training params\nnum_epochs = 100\ngenerator_rounds = 1        # Note we train generator less than critic in WGAN\ncritic_rounds = 1           # Note we use name critic (not discriminator) in WGAN. It is deliberate.\nclip_value = 0.01","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T18:59:26.596051Z","iopub.execute_input":"2025-08-22T18:59:26.596334Z","iopub.status.idle":"2025-08-22T18:59:26.603472Z","shell.execute_reply.started":"2025-08-22T18:59:26.596314Z","shell.execute_reply":"2025-08-22T18:59:26.602903Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Transform\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.5,), std=(0.5,))\n])\nprint(f\"Transform to be applied:\\n{transform}\\n\")\n\n# Load MNIST\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\nprint(f\"Train data:\\n{train_dataset}\\n\")\n\n# Dataloader\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True) # Last batch will be 96 (6000 % 128) instead of 128, so drop to avoid problem with batch norm\nprint(f\"Data loader:\\n{train_loader}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T19:21:26.532849Z","iopub.execute_input":"2025-08-22T19:21:26.533153Z","iopub.status.idle":"2025-08-22T19:21:26.619067Z","shell.execute_reply.started":"2025-08-22T19:21:26.533133Z","shell.execute_reply":"2025-08-22T19:21:26.618235Z"}},"outputs":[{"name":"stdout","text":"Transform to be applied:\nCompose(\n    ToTensor()\n    Normalize(mean=(0.5,), std=(0.5,))\n)\n\nTrain data:\nDataset MNIST\n    Number of datapoints: 60000\n    Root location: ./data\n    Split: Train\n    StandardTransform\nTransform: Compose(\n               ToTensor()\n               Normalize(mean=(0.5,), std=(0.5,))\n           )\n\nData loader:\n<torch.utils.data.dataloader.DataLoader object at 0x7a876d76b8d0>\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"dz = 128\nz_fixed = torch.randn(64, dz, device=device)\nz_fixed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T19:01:08.675671Z","iopub.execute_input":"2025-08-22T19:01:08.675973Z","iopub.status.idle":"2025-08-22T19:01:09.368343Z","shell.execute_reply.started":"2025-08-22T19:01:08.675951Z","shell.execute_reply":"2025-08-22T19:01:09.367722Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"tensor([[ 0.1940,  2.1614, -0.1721,  ..., -1.2072, -0.2438, -0.6784],\n        [ 0.1973,  0.9782, -0.0287,  ..., -0.9226,  0.7893, -1.8010],\n        [-1.9351,  1.1007,  0.0251,  ..., -0.6872, -0.0919, -0.7132],\n        ...,\n        [-1.0439,  0.7082,  0.0871,  ..., -0.2350,  0.6789, -0.2683],\n        [ 0.1728,  0.9311,  0.9508,  ..., -1.2910, -0.3644,  0.9805],\n        [-0.5130,  0.6719, -0.1551,  ..., -1.0449,  1.5397, -2.0042]],\n       device='cuda:0')"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## Model   ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Optimizers  ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training loop  ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training  ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Questions  ","metadata":{}},{"cell_type":"markdown","source":"### E1  ","metadata":{}},{"cell_type":"code","source":"train_dataset.classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T19:15:34.981397Z","iopub.execute_input":"2025-08-22T19:15:34.981673Z","iopub.status.idle":"2025-08-22T19:15:34.986848Z","shell.execute_reply.started":"2025-08-22T19:15:34.981655Z","shell.execute_reply":"2025-08-22T19:15:34.986137Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"['0 - zero',\n '1 - one',\n '2 - two',\n '3 - three',\n '4 - four',\n '5 - five',\n '6 - six',\n '7 - seven',\n '8 - eight',\n '9 - nine']"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"counts = torch.bincount(train_dataset.targets)\ncounts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T19:17:06.721857Z","iopub.execute_input":"2025-08-22T19:17:06.722573Z","iopub.status.idle":"2025-08-22T19:17:06.727700Z","shell.execute_reply.started":"2025-08-22T19:17:06.722549Z","shell.execute_reply":"2025-08-22T19:17:06.726999Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"tensor([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949])"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"torch.max(counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T19:17:53.807406Z","iopub.execute_input":"2025-08-22T19:17:53.807679Z","iopub.status.idle":"2025-08-22T19:17:53.813447Z","shell.execute_reply.started":"2025-08-22T19:17:53.807657Z","shell.execute_reply":"2025-08-22T19:17:53.812751Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"tensor(6742)"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"torch.max(counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T19:17:59.764826Z","iopub.execute_input":"2025-08-22T19:17:59.765363Z","iopub.status.idle":"2025-08-22T19:17:59.770370Z","shell.execute_reply.started":"2025-08-22T19:17:59.765340Z","shell.execute_reply":"2025-08-22T19:17:59.769845Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"tensor(5421)"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"(torch.max(counts) - torch.min(counts)) / counts.float().mean() * 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T19:38:57.058157Z","iopub.execute_input":"2025-08-22T19:38:57.058415Z","iopub.status.idle":"2025-08-22T19:38:57.064361Z","shell.execute_reply.started":"2025-08-22T19:38:57.058397Z","shell.execute_reply":"2025-08-22T19:38:57.063667Z"}},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"tensor(22.0167)"},"metadata":{}}],"execution_count":67},{"cell_type":"markdown","source":"### E2  ","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\n\n# Use your already-defined train_dataset (with ToTensor + Normalize((0.5,), (0.5,)))\nloader = DataLoader(train_dataset, batch_size=256, shuffle=True, drop_last=True)\n\n# Grab exactly the first batch after transforms\nX, _ = next(iter(loader))              # X shape: [B, C, H, W], dtype float32 in [-1, 1]\n\n# Compute stats on the batch tensor\nmu = X.mean().item()\nsigma = X.std(unbiased=False).item()   # population std to match spec-style reporting\nm = X.min().item()\nM = X.max().item()\n\n# p = fraction of pixels with |x| <= 0.5\np = (X.abs() <= 0.5).float().mean().item()\n\nprint( round(mu, 3), round(sigma, 3), round(m, 3), round(M, 3), round(p, 3) )\n# -> (µ, σ, m, M, p)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T19:36:58.826221Z","iopub.execute_input":"2025-08-22T19:36:58.826874Z","iopub.status.idle":"2025-08-22T19:36:58.900307Z","shell.execute_reply.started":"2025-08-22T19:36:58.826849Z","shell.execute_reply":"2025-08-22T19:36:58.899660Z"}},"outputs":[{"name":"stdout","text":"-0.742 0.613 -1.0 1.0 0.05\n","output_type":"stream"}],"execution_count":60}]}